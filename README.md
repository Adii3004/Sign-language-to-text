# Sign-language-to-text

This project focuses on developing an efficient model for real-time recognition of American Sign Language (ASL) gestures, translating them into text for enhanced communication accessibility. Leveraging computer vision techniques and machine learning, the system captures live video input, tracks hand gestures using the MediaPipe Hands library, and employs a trained Random Forest Classifier to predict ASL signs.
